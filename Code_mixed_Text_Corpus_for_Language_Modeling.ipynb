{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-Mw2CzgQOvUt",
        "Hvz0-RWEte2s",
        "jV4ishli_nrw",
        "uFqylmt0tk9L",
        "qp9OUpOBCJIt",
        "uX7s-9RMCtt1",
        "A-EQAOu07HEs"
      ],
      "authorship_tag": "ABX9TyOpE9oVc4CUbGpO3rAuYVkm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40d7dde7c3c640e88bd39747d5d06d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d18545987b420cb7f5bac483344a3f",
              "IPY_MODEL_97c43afe68af43758b8c25ce21a22685",
              "IPY_MODEL_4d0f496fcbc74236a0f2e0cb49c74f26"
            ],
            "layout": "IPY_MODEL_0174e5465a0a42f7902f74723aec46b5"
          }
        },
        "75d18545987b420cb7f5bac483344a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6011fd2c864e4e478f0fecf8f34c6d86",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd5a75e34d94738abc540fa8717dd08",
            "value": "Processing line: 100%"
          }
        },
        "97c43afe68af43758b8c25ce21a22685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64138ca860784f69ad4104c03c3ac5dc",
            "max": 3228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f60762ce5a6b44eb9766b2705b00839b",
            "value": 3228
          }
        },
        "4d0f496fcbc74236a0f2e0cb49c74f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d06dd8eadbbe4d1c80d9d52cfdbc5c78",
            "placeholder": "​",
            "style": "IPY_MODEL_a557388ae3c04060aa9c15a96663c304",
            "value": " 3228/3228 [00:00&lt;00:00, 18302.69it/s]"
          }
        },
        "0174e5465a0a42f7902f74723aec46b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6011fd2c864e4e478f0fecf8f34c6d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd5a75e34d94738abc540fa8717dd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64138ca860784f69ad4104c03c3ac5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60762ce5a6b44eb9766b2705b00839b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d06dd8eadbbe4d1c80d9d52cfdbc5c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a557388ae3c04060aa9c15a96663c304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adkta/speech_text_dataset_creation/blob/main/Code_mixed_Text_Corpus_for_Language_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CORPUS SOURCES (STILL COMPILING)\n",
        "\n",
        "https://www.kaggle.com/datasets/thedevastator/unlock-universal-language-with-the-lince-dataset?select=lid_nepeng_train.csv\n",
        "https://github.com/nirajpahari/nepali-english-cs-sentiment\n",
        "\n",
        "https://emnlp2014.org/workshops/codeswitch/call.html"
      ],
      "metadata": {
        "id": "36MZ7YgJT2m5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SET-UP"
      ],
      "metadata": {
        "id": "-Mw2CzgQOvUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip==24.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ymg49K54scr",
        "outputId": "b7557e0f-3076-4555-a73c-1e5bd6bf668e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip==24.0\n",
            "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy6bsznoNQ6v",
        "outputId": "87cb316a-8db2-48f3-9a27-17cf51501e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/transliteration.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DoOwpTewo8u",
        "outputId": "a51d9c08-2101-4493-8425-998feeb60c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transliteration'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 154 (delta 84), reused 98 (delta 39), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (154/154), 38.10 KiB | 3.46 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ROMANIZED NEPALI TO DEVANAGARI TRANSLITERATION"
      ],
      "metadata": {
        "id": "EuflhQ2YO2W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ROMANIZED NEP TRANSLITERATION DICTIONARY"
      ],
      "metadata": {
        "id": "Hvz0-RWEte2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/drive/MyDrive/MSICE/Romanized_Nepali_Transliteration/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD4NYsut_hVC",
        "outputId": "26d8a9be-bd26-4224-8ef6-7a02bfc971cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 99M\n",
            "-rw------- 1 root root 67M Oct 31 17:09 AI4Bharat_Aksharantar_nep.zip\n",
            "-rw------- 1 root root 32M Oct 31 17:10 romanized_nep_transliteration_dic.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MSICE/Romanized_Nepali_Transliteration/romanized_nep_transliteration_dic.zip /content/"
      ],
      "metadata": {
        "id": "C54_YwihCKfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -l /content/romanized_nep_transliteration_dic.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoIOUEYpCOTm",
        "outputId": "a943522c-dccb-4082-f431-aba21aaa96da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/romanized_nep_transliteration_dic.zip\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "105644385  2025-10-31 17:02   content/romanized_nep_transliteration_dic.json\n",
            "---------                     -------\n",
            "105644385                     1 file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/romanized_nep_transliteration_dic.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnVwfbZHCVIi",
        "outputId": "1702e27b-7275-4d30-9c3b-0be1d1e5b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/romanized_nep_transliteration_dic.zip\n",
            "  inflating: content/romanized_nep_transliteration_dic.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transliteration.transliterator import TranslitDict\n",
        "roman_nep_translit = TranslitDict.load('/content/romanized_nep_transliteration_dic.json')"
      ],
      "metadata": {
        "id": "HWZaiPN5CHZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9VJLDjsDQ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####ADD TO CURRENT ROMANIZED NEP TRANSLIT DICTIONARY"
      ],
      "metadata": {
        "id": "jV4ishli_nrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MSICE/Romanized_Nepali_Transliteration/AI4Bharat_Aksharantar_nep.zip /content/"
      ],
      "metadata": {
        "id": "_-TyQMzswvA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -l AI4Bharat_Aksharantar_nep.zip"
      ],
      "metadata": {
        "id": "ThR_mIJXw3-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/romanized_nep\n",
        "!unzip AI4Bharat_Aksharantar_nep.zip -d /content/romanized_nep"
      ],
      "metadata": {
        "id": "dLrbY2SOw5r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/romanized_nep/nep_train.json| wc -l"
      ],
      "metadata": {
        "id": "x8XrFaTqxDWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "folder = Path('/content/romanized_nep')\n",
        "\n",
        "romanized_nep_dict = dict()\n",
        "for f in folder.iterdir():\n",
        "    if f.is_dir():\n",
        "        continue\n",
        "    if 'json' not in f.name:\n",
        "        continue\n",
        "\n",
        "    with open(f, 'r') as translit_file:\n",
        "        for line in translit_file:\n",
        "            line = line.strip()\n",
        "            entry = json.loads(line) #a dictionary\n",
        "            romanized_nep_dict[entry['english word']] = entry['native word']"
      ],
      "metadata": {
        "id": "QvU3X4efxEax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(romanized_nep_dict)"
      ],
      "metadata": {
        "id": "6EvxO_DPxI6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counterr = 0\n",
        "for k, v in romanized_nep_dict.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "    counterr += 1\n",
        "    if counterr == 5:\n",
        "        break"
      ],
      "metadata": {
        "id": "VTrmrZsfxQjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transliteration.transliterator import TranslitDict\n",
        "translit_dict = TranslitDict()\n",
        "translit_dict.update(romanized_nep_dict)\n",
        "translit_dict.export('/content/romanized_nep_transliteration_dic.json')"
      ],
      "metadata": {
        "id": "1wq4sTblxV2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9Dl_k4KynHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ML MODELS FOR TRANSLITERATION"
      ],
      "metadata": {
        "id": "uFqylmt0tk9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AI4BHARAT IndicXlit\n",
        "\n",
        "Source: https://github.com/AI4Bharat/IndicXlit\n",
        "\n",
        "Reference: https://colab.research.google.com/drive/1P78Tbr6zhe-5LeiKk525N3SGPKn2ofGg?usp=sharing"
      ],
      "metadata": {
        "id": "qp9OUpOBCJIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBJTKILzyh43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b4ffa23-845c-4002-c65f-324c7ef0d913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ai4bharat-transliteration\n",
            "  Downloading ai4bharat_transliteration-1.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pydload (from ai4bharat-transliteration)\n",
            "  Downloading pydload-1.0.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from ai4bharat-transliteration) (3.1.2)\n",
            "Collecting flask-cors (from ai4bharat-transliteration)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting gevent (from ai4bharat-transliteration)\n",
            "  Downloading gevent-25.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (14 kB)\n",
            "Collecting sacremoses (from ai4bharat-transliteration)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ai4bharat-transliteration) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai4bharat-transliteration) (4.67.1)\n",
            "Collecting ujson (from ai4bharat-transliteration)\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Collecting mock (from ai4bharat-transliteration)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting tensorboardX (from ai4bharat-transliteration)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from ai4bharat-transliteration) (18.1.0)\n",
            "Collecting fairseq (from ai4bharat-transliteration)\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-1.1.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting indic-nlp-library (from ai4bharat-transliteration)\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (3.0.12)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting omegaconf<2.1 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (2.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (2024.11.6)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (2.8.0+cu126)\n",
            "Collecting bitarray (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading bitarray-3.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fairseq->ai4bharat-transliteration) (2.8.0+cu126)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask->ai4bharat-transliteration) (3.1.3)\n",
            "Requirement already satisfied: greenlet>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from gevent->ai4bharat-transliteration) (3.2.4)\n",
            "Collecting zope.event (from gevent->ai4bharat-transliteration)\n",
            "  Downloading zope_event-6.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting zope.interface (from gevent->ai4bharat-transliteration)\n",
            "  Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-argparse (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ai4bharat-transliteration) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ai4bharat-transliteration) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ai4bharat-transliteration) (2025.2)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.12/dist-packages (from pydload->ai4bharat-transliteration) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pydload->ai4bharat-transliteration) (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses->ai4bharat-transliteration) (1.5.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX->ai4bharat-transliteration) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX->ai4bharat-transliteration) (5.29.5)\n",
            "Collecting tf2crf (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-datasets~=3.1 (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "INFO: pip is looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-1.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading urduhack-1.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading urduhack-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading urduhack-1.0.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading urduhack-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Downloading urduhack-0.3.4-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting transformers~=2.10 (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-0.3.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is still looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading urduhack-0.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tensorflow~=2.2 in /usr/local/lib/python3.12/dist-packages (from urduhack->ai4bharat-transliteration) (2.19.0)\n",
            "  Downloading urduhack-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading urduhack-0.2.7-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading regex-2019.12.20.tar.gz (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.8/679.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-0.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "  Downloading urduhack-0.2.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading urduhack-0.2.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading urduhack-0.2.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading urduhack-0.2.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading urduhack-0.2.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading urduhack-0.1.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->ai4bharat-transliteration)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ai4bharat-transliteration) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->fairseq->ai4bharat-transliteration) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->fairseq->ai4bharat-transliteration) (2.23)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from progressbar2->pydload->ai4bharat-transliteration) (3.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pydload->ai4bharat-transliteration) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pydload->ai4bharat-transliteration) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pydload->ai4bharat-transliteration) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pydload->ai4bharat-transliteration) (2025.8.3)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting setuptools (from torch->fairseq->ai4bharat-transliteration)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->fairseq->ai4bharat-transliteration) (1.3.0)\n",
            "Downloading ai4bharat_transliteration-1.1.3-py3-none-any.whl (32 kB)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading gevent-25.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading pydload-1.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urduhack-0.1.4-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitarray-3.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.9/332.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope_event-6.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp312-cp312-linux_x86_64.whl size=11324520 sha256=27c867004c86cc9e2616fb59243e5db9594b4c2cfc6e11fa24a1fc862e3b9177\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/f8/a7/58ad0492b276ba117d7fb01ec38a447a3b1ae9c535952e1c9f\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=6efb06912b4fcf1abd1fd37004f26c04a5e5b9b3c36a4911e58024b73748a907\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/92/b7/08c6a108fc5bf6370a7540d11bbe9befc99b7e045ac7558d49\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: morfessor, bitarray, antlr4-python3-runtime, zope.interface, urduhack, ujson, tensorboardX, setuptools, sacremoses, portalocker, omegaconf, mock, colorama, zope.event, sacrebleu, hydra-core, sphinxcontrib-jquery, sphinx-argparse, pydload, gevent, flask-cors, sphinx-rtd-theme, indic-nlp-library, fairseq, ai4bharat-transliteration\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
            "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: omegaconf\n",
            "    Found existing installation: omegaconf 2.3.0\n",
            "    Uninstalling omegaconf-2.3.0:\n",
            "      Successfully uninstalled omegaconf-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ai4bharat-transliteration-1.1.3 antlr4-python3-runtime-4.8 bitarray-3.7.1 colorama-0.4.6 fairseq-0.12.2 flask-cors-6.0.1 gevent-25.9.1 hydra-core-1.0.7 indic-nlp-library-0.92 mock-5.2.0 morfessor-2.0.6 omegaconf-2.0.6 portalocker-3.2.0 pydload-1.0.9 sacrebleu-2.5.1 sacremoses-0.1.1 setuptools-80.9.0 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 tensorboardX-2.6.4 ujson-5.11.0 urduhack-0.1.4 zope.event-6.0 zope.interface-8.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "sphinxcontrib"
                ]
              },
              "id": "90d2035124ab42e4acead88c877a8d10"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install ai4bharat-transliteration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FILES TO CHANGE/COPY\n",
        "# /usr/local/lib/python3.12/dist-packages/fairseq/dataclass/configs.py\n",
        "# /usr/local/lib/python3.12/dist-packages/hydra/conf/__init__.py\n",
        "# /usr/local/lib/python3.12/dist-packages/fairseq/dataclass/initialize.py\n",
        "# /usr/local/lib/python3.12/dist-packages/fairseq/models/transformer/transformer_config.py\n",
        "# /usr/local/lib/python3.12/dist-packages/hydra/core/plugins.py\n",
        "# /usr/local/lib/python3.12/dist-packages/fairseq/checkpoint_utils.py\n",
        "!cp -r /content/drive/MyDrive/MSICE/Dependency\\ Corrections/IndicXlit-Corrections/* /usr/local/lib/python3.12/dist-packages/"
      ],
      "metadata": {
        "id": "am9EWhfKOhdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ai4bharat.transliteration import XlitEngine"
      ],
      "metadata": {
        "id": "VLq0ybS64U2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intializing the en-indic multilingual model and dictionaries (if rerank option is True)\n",
        "e = XlitEngine(\"ne\", beam_width=4, rescore=True, src_script_type = \"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-2_ztI7BJs",
        "outputId": "fe52d6b8-4773-4abd-98b4-8da296dc47cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(121.0 of 121.0)\u001b[39m |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.12/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/model.zip\n",
            "Models downloaded to: /usr/local/lib/python3.12/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0\n",
            "NOTE: When uninstalling this library, REMEMBER to delete the models manually\n",
            "Downloading language model probablitites dictionaries for rescoring module\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(812.0 of 812.0)\u001b[39m |################| Elapsed Time: 0:00:05 Time:  0:00:05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.12/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/dicts.zip\n",
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dicts into RAM: 100%|██████████| 1/1 [00:06<00:00,  6.74s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Transliteration\\ Dictionary/words_to_transliterate.dic /content/"
      ],
      "metadata": {
        "id": "acZve09LPOJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transliterate word\n",
        "# out = e.translit_word(\"janney\", topk=4)\n",
        "# print(out)"
      ],
      "metadata": {
        "id": "vn8kYdDy7TwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/words_to_transliterate.dic', 'r') as f, \\\n",
        "#     open('/content/devanagarized_english.dic', 'w', encoding = 'utf-8') as o_f:\n",
        "#     for line in f:\n",
        "#         word = line.strip()\n",
        "#         xlit = e.translit_word(word, topk=1)\n",
        "#         print(f\"{word}: {xlit}\", file=o_f)"
      ],
      "metadata": {
        "id": "eGUGkJiAPpe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transliterate sentence\n",
        "# e = XlitEngine([\"te\", 'mr'], beam_width=10, src_script_type = \"en\")\n",
        "# out = e.translit_sentence(\"big question, big no ,. he is 100% jhuttt murder ho yo\")\n",
        "# print(out)"
      ],
      "metadata": {
        "id": "Wq19Dot4DQWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####INDIC-TRANS"
      ],
      "metadata": {
        "id": "uX7s-9RMCtt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pbr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVmngeVFE_TG",
        "outputId": "d925c0e7-8a90-469a-c8ba-84653eb04cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pbr\n",
            "  Downloading pbr-7.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pbr) (75.2.0)\n",
            "Downloading pbr-7.0.1-py2.py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.1/126.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr\n",
            "Successfully installed pbr-7.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/libindic/indic-trans.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPTVSVKKE6hk",
        "outputId": "25323c9d-47cb-40e6-cef3-356049092cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic-trans'...\n",
            "remote: Enumerating objects: 2225, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 2225 (delta 8), reused 10 (delta 3), pack-reused 2206 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2225/2225), 516.51 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (1102/1102), done.\n",
            "Updating files: 100% (719/719), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/indic-trans\n",
        "!pip install .\n",
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzf0VpioFEFZ",
        "outputId": "f219b685-8a61-4f95-ab15-b87dd13ad90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/indic-trans\n",
            "Processing /content/indic-trans\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pbr in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (7.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (1.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (1.0.0)\n",
            "Requirement already satisfied: cython>=0.24.0a0 in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.12/dist-packages (from indictrans==1.2.3) (1.16.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pbr->indictrans==1.2.3) (75.2.0)\n",
            "Building wheels for collected packages: indictrans\n",
            "  Building wheel for indictrans (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indictrans: filename=indictrans-1.2.3-cp312-cp312-linux_x86_64.whl size=337927530 sha256=366e96bd3ccc98d122123b421daa2cf7067a6a5ad5f7b4b4d77092f63b202c4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/33/a1/497e992a835627b16b40b880d71d8a32fdf05759df6cf7fddb\n",
            "Successfully built indictrans\n",
            "Installing collected packages: indictrans\n",
            "Successfully installed indictrans-1.2.3\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/Dependency\\ Corrections/libindic_indic-trans_corrections/* /usr/local/lib/python3.12/dist-packages/"
      ],
      "metadata": {
        "id": "T34OM1iaJJXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from indictrans import Transliterator\n",
        "trn = Transliterator(source='eng', target='nep')"
      ],
      "metadata": {
        "id": "ELSlRvy1FR0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "EYFekdF9CTN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SPELL CORRECTION\n",
        "\n",
        "Options:\n",
        "1) Using distance from a vocab\n",
        "2) Using LM"
      ],
      "metadata": {
        "id": "A-EQAOu07HEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SPELLING CORRECTION (BASED ON NEPALI CORPUS)\n",
        "\n",
        "Large News Corpus from kaggle: ashokpant/nepali-news-dataset-large"
      ],
      "metadata": {
        "id": "owB-LPX1T7bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DOWNLOAD CORPUS"
      ],
      "metadata": {
        "id": "kd6I0GyIYJla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -j /content/drive/MyDrive/MSICE/real_time_test-20240823T071018Z-001.zip real_time_test/char_map.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6yOSvlZT6hL",
        "outputId": "9c4bed2e-11f0-44d9-f78f-41971baaa826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/MSICE/real_time_test-20240823T071018Z-001.zip\n",
            "  inflating: char_map.py             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download ashokpant/nepali-news-dataset-large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbPeO4BWuUN",
        "outputId": "5569efee-53f3-47d6-da70-13394e79a84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ashokpant/nepali-news-dataset-large\n",
            "License(s): GPL-2.0\n",
            "Downloading nepali-news-dataset-large.zip to /content\n",
            "  0% 0.00/16.5M [00:00<?, ?B/s]\n",
            "100% 16.5M/16.5M [00:00<00:00, 1.24GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -j nepali-news-dataset-large.zip nepali_news_dataset_20_categories_large.tar.xz -d /content/\n",
        "!tar xf /content/nepali_news_dataset_20_categories_large.tar.xz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVYyepZRX2x0",
        "outputId": "bf2779bd-a4c9-4186-8abb-8d61ca3e3a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nepali-news-dataset-large.zip\n",
            "  inflating: /content/nepali_news_dataset_20_categories_large.tar.xz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####EXTRACT WORD-COUNT DICTIONARY FROM CORPUS"
      ],
      "metadata": {
        "id": "eB-x_P9yXpsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSplittingRegex(strip_chars):\n",
        "  splitting_list = []\n",
        "  meta_chars = ['?','.','[','{','(',')','^','$','|','*','+']\n",
        "  for strip_char in strip_chars:\n",
        "    if strip_char in meta_chars:\n",
        "      strip_char = f'\\{strip_char}'\n",
        "\n",
        "\n",
        "    if strip_char != ' ':\n",
        "      splitting_list.append('\\s+'+strip_char+'\\s+')\n",
        "      splitting_list.append('\\s+'+strip_char)\n",
        "      splitting_list.append(strip_char+'\\s+')\n",
        "      splitting_list.append(strip_char)\n",
        "\n",
        "  splitting_list.append('\\s+')\n",
        "  splitting_regex='|'.join(splitting_list)\n",
        "  print(splitting_regex)\n",
        "  return splitting_regex\n",
        "\n",
        "import chardet\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        detector = chardet.universaldetector.UniversalDetector()\n",
        "        for line in file:\n",
        "            detector.feed(line)\n",
        "            if detector.done:\n",
        "                break\n",
        "        detector.close()\n",
        "    return detector.result['encoding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQyFshvyXa6y",
        "outputId": "f6dcee0f-e8be-4e5a-db25-98eff6a572b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\{'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\{'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-2030336051.py:6: SyntaxWarning: invalid escape sequence '\\{'\n",
            "  strip_char = f'\\{strip_char}'\n",
            "/tmp/ipython-input-2030336051.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  splitting_list.append('\\s+'+strip_char+'\\s+')\n",
            "/tmp/ipython-input-2030336051.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  splitting_list.append('\\s+'+strip_char+'\\s+')\n",
            "/tmp/ipython-input-2030336051.py:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  splitting_list.append('\\s+'+strip_char)\n",
            "/tmp/ipython-input-2030336051.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  splitting_list.append(strip_char+'\\s+')\n",
            "/tmp/ipython-input-2030336051.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  splitting_list.append('\\s+')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "WORDS = Counter()\n",
        "\n",
        "strip_chars = ' !?,.।()'\n",
        "split_regex = getSplittingRegex(strip_chars)\n",
        "\n",
        "file_paths = Path('/content/nepali_news_dataset_20_categories_large').rglob('*.txt')\n",
        "total_files = len(list(file_paths))\n",
        "file_count = 1\n",
        "\n",
        "file_paths = Path('/content/nepali_news_dataset_20_categories_large').rglob('*.txt')\n",
        "print(f'Total files = {total_files}')\n",
        "unsuccessful_reads = []\n",
        "unsuccessful_splits = []\n",
        "for file_path in file_paths:\n",
        "\n",
        "  enc = detect_encoding(file_path)\n",
        "  with open(file_path,'r',encoding=enc) as f:\n",
        "    print(f'Processing {file_count} of {total_files} files. File: {file_path}...', end='\\r')\n",
        "    try:\n",
        "      file_data = f.read().strip()\n",
        "    except:\n",
        "      unsuccessful_reads.append(file_path)\n",
        "\n",
        "    try:\n",
        "      WORDS.update(re.split(split_regex,file_data))\n",
        "    except:\n",
        "      unsuccessful_splits.append(file_path)\n",
        "\n",
        "    file_count+=1\n",
        "\n",
        "print(f\"Unsucessful reads: {len(unsuccessful_reads)} files\")\n",
        "print(f\"Unsucessful splits: {len(unsuccessful_splits)} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na3XbwfRXm0S",
        "outputId": "4166807a-3784-4dbf-83cb-a4af178002bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\s+!\\s+|\\s+!|!\\s+|!|\\s+\\?\\s+|\\s+\\?|\\?\\s+|\\?|\\s+,\\s+|\\s+,|,\\s+|,|\\s+\\.\\s+|\\s+\\.|\\.\\s+|\\.|\\s+।\\s+|\\s+।|।\\s+|।|\\s+\\(\\s+|\\s+\\(|\\(\\s+|\\(|\\s+\\)\\s+|\\s+\\)|\\)\\s+|\\)|\\s+\n",
            "Total files = 6973\n",
            "Unsucessful reads: 81 files\n",
            "Unsucessful splits: 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SPELLING CORRECTION LOGIC"
      ],
      "metadata": {
        "id": "EsENFtimYSBT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61Um3B9lXCul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EMNLP Code-Switched LID Dataset"
      ],
      "metadata": {
        "id": "b890oMA9DTsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle/\n",
        "!cp /content/drive/MyDrive/Workspace/Kaggle/API_KEY/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "yEjEbLi2S2HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download thedevastator/unlock-universal-language-with-the-lince-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To1HNKUfTJ_t",
        "outputId": "12e6d9be-58b7-410a-b3b1-580ecb38f8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/thedevastator/unlock-universal-language-with-the-lince-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading unlock-universal-language-with-the-lince-dataset.zip to /content\n",
            "  0% 0.00/11.3M [00:00<?, ?B/s]\n",
            "100% 11.3M/11.3M [00:00<00:00, 1.10GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/LM_CM_Dataset"
      ],
      "metadata": {
        "id": "2c3afP_HWWtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -j /content/unlock-universal-language-with-the-lince-dataset.zip lid_nepeng_train.csv lid_nepeng_test.csv lid_nepeng_validation.csv -d /content/LM_CM_Dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ6PxfdVYg9O",
        "outputId": "f4c7db22-ddd4-43bd-aa2b-c4983ee098f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/unlock-universal-language-with-the-lince-dataset.zip\n",
            "  inflating: /content/LM_CM_Dataset/lid_nepeng_test.csv  \n",
            "  inflating: /content/LM_CM_Dataset/lid_nepeng_train.csv  \n",
            "  inflating: /content/LM_CM_Dataset/lid_nepeng_validation.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/LM_CM_Dataset/lid_nepeng_train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr_-Q75X3SHO",
        "outputId": "ff8f90e7-21b8-43a8-aaf4-6354626fbbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25356 /content/LM_CM_Dataset/lid_nepeng_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#COMBINING FILES\n",
        "comb_in_file = '/content/nep_eng_train_valid_combined.csv'\n",
        "in_files = ['/content/LM_CM_Dataset/lid_nepeng_test.csv']\n",
        "# in_files = ['/content/LM_CM_Dataset/lid_nepeng_train.csv', '/content/LM_CM_Dataset/lid_nepeng_validation.csv', '/content/LM_CM_Dataset/lid_nepeng_test.csv']\n",
        "with open (comb_in_file, 'w', encoding = 'utf-8') as out_f:\n",
        "    for f in in_files:\n",
        "        with open(f, 'r', encoding = 'utf-8') as in_f:\n",
        "            for line in in_f:\n",
        "                print(line.strip(), file=out_f)\n"
      ],
      "metadata": {
        "id": "YvFR7vL4dBSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/nep_eng_train_valid_combined.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU6tfM31iUWG",
        "outputId": "29b7f583-9694-4c36-ff97-28540ea335d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx,words,lid\n",
            "0,\"['@dg_no_9' 'Khasai' 'kei' 'hoina' ',' 'liverpool' 'jitera' '@Jangiz_'\n",
            "'lai' 'nadekhda' 'chai' 'TL' 'bore' 'huni' 'raicha' 'bhanya' 'matra' 'ho'\n",
            "':-)']\",\"['other' 'lang2' 'lang2' 'lang2' 'other' 'ne' 'lang2' 'other' 'lang2'\n",
            "'lang2' 'lang2' 'ne' 'lang1' 'lang2' 'lang2' 'lang2' 'lang2' 'lang2'\n",
            "'other']\"\n",
            "1,\"['Yo' '@Jangiz_' 'TL' 'ma' 'nabha' 'aja' 'chai' 'lastai' 'bore' 'bho'\n",
            "'kya' ':P' '#LFC' ':D']\",\"['lang2' 'other' 'ne' 'lang2' 'lang2' 'lang2' 'lang2' 'lang2' 'lang1'\n",
            "'lang2' 'lang2' 'other' 'lang1' 'other']\"\n",
            "2,\"['@mkhkopite' 'Yooo' '!!' 'Wt' 'did' 'I' 'tell' 'you' 'early' 'morning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_LIDS = ('other', 'lang1', 'lang2', 'ne')\n",
        "NEP_LIDS = ('lang2', 'ne')\n",
        "ENG_LIDS = ('lang1',)\n",
        "NEP_ENG_LIDS = NEP_LIDS + ENG_LIDS\n",
        "\n",
        "def filter_text(words: list[str], lids: list[str]) -> tuple[list[str], list[str]]:\n",
        "    o_words = []\n",
        "    o_lids = []\n",
        "    for word, lid in zip(words, lids):\n",
        "        # if lid not in ALL_LIDS: #to check for any unexpected lids\n",
        "        #     print(lid)\n",
        "        if lid in NEP_ENG_LIDS:\n",
        "            o_words.append(word)\n",
        "            o_lids.append(lid)\n",
        "    return (o_words, o_lids)\n",
        "\n",
        "def get_native(words: list[str], lids: list[str]) -> str:\n",
        "    \"\"\"\n",
        "    lang1 = eng, lang2 = nep, ne = nep in the LINCE dataset\n",
        "    Either uses a Romanized Nepali Transliteration Dictionary or ML models such as IndicTrans or IndicXLit\n",
        "    When using Romanized Nepali Transliteration Dictionary, if it cannot find the Romanized Nepali word, it simply keeps the word as is\n",
        "    \"\"\"\n",
        "    native_txt = []\n",
        "    eng_words = set()\n",
        "    for word, lid in zip(words, lids):\n",
        "        native_txt.append(word)\n",
        "        # if lid in ENG_LIDS:\n",
        "        #     native_txt.append(word)\n",
        "        # elif lid in NEP_LIDS:\n",
        "        #     native_txt.append(word)\n",
        "            # native_txt.append(e.translit_word(word, topk=1).get('ne')[0]) #Using AI4Bharat's transliteration model IndicXLit\n",
        "            # native_txt.append(trn.transform(word)) #Using IndicTrans\n",
        "            # native_txt.append(correct(trn.transform(word))) #Using with spelling correction\n",
        "            # if word in roman_nep_translit:\n",
        "            #     native_txt.append(roman_nep_translit.get(word)) #Using with spelling correction\n",
        "            # else:\n",
        "            #     native_txt.append(word)\n",
        "    return \" \".join(native_txt)\n",
        "\n",
        "def get_attr_list(attr_txt: str) -> str:\n",
        "    attr_txt = attr_txt.replace(\"\\n\",\" \") # within the cell the words are split by space and new line characters\n",
        "    return re.sub(pattern, \"\", attr_txt).split(\" \")\n"
      ],
      "metadata": {
        "id": "uceDdgf3i4Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERTING TO Code-mixed Native Format\n",
        "\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "native_file = '/content/emnlp_2014_cm_lm_corpus.txt'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/nep_eng_train_valid_combined.csv')\n",
        "\n",
        "with open(native_file, 'w', encoding = 'utf-8') as out_f:\n",
        "    pattern = re.compile(r\"[\\[\\]',]\") #single quote, double quote, square brackets\n",
        "    tot_lines = len(df)\n",
        "    for line_count in tqdm(range(0, tot_lines), desc = \"Processing line\"):\n",
        "        words = get_attr_list(df.loc[line_count, 'words'])\n",
        "        lids = get_attr_list(df.loc[line_count, 'lid'])\n",
        "        words, lids = filter_text(words, lids) #remove twitter handle and get only nepali and english text\n",
        "        native_txt = get_native(words, lids) #convert to native script\n",
        "        print(native_txt, file=out_f) #write corpus to file line by line\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "40d7dde7c3c640e88bd39747d5d06d9f",
            "75d18545987b420cb7f5bac483344a3f",
            "97c43afe68af43758b8c25ce21a22685",
            "4d0f496fcbc74236a0f2e0cb49c74f26",
            "0174e5465a0a42f7902f74723aec46b5",
            "6011fd2c864e4e478f0fecf8f34c6d86",
            "6fd5a75e34d94738abc540fa8717dd08",
            "64138ca860784f69ad4104c03c3ac5dc",
            "f60762ce5a6b44eb9766b2705b00839b",
            "d06dd8eadbbe4d1c80d9d52cfdbc5c78",
            "a557388ae3c04060aa9c15a96663c304"
          ]
        },
        "id": "BI6Hn7FVfXZ7",
        "outputId": "7a9ea5e0-84c9-47e8-f216-d6f6ed4777f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing line:   0%|          | 0/3228 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d7dde7c3c640e88bd39747d5d06d9f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/emnlp_2014_cm_lm_corpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJXWU-2nYQfj",
        "outputId": "1f484475-6518-4f82-c861-13807abf52ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/MSICE/CM_Text_Corpus/"
      ],
      "metadata": {
        "id": "qU4_V3wM15Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/emnlp_2014_cm_lm_corpus.txt /content/drive/MyDrive/MSICE/CM_Text_Corpus/emnlp_2014_cm_train_valid_onlyeng_corpus.txt"
      ],
      "metadata": {
        "id": "8uNRwp1y2Dk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SENTIMENT ID PAHARI 2024 DATASET"
      ],
      "metadata": {
        "id": "oJy_JrJD4nY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nirajpahari/nepali-english-cs-sentiment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvfikVjG4rKv",
        "outputId": "c26da728-d3c5-401f-882f-d07895d91754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nepali-english-cs-sentiment'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 26 (delta 8), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (26/26), 393.50 KiB | 3.05 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/nepali-english-cs-sentiment/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi_NUhcA4vc5",
        "outputId": "a8033b1c-5c9a-4ab3-c901-aaa868648e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LICENSE  README.md  test.tsv  train.tsv  val.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/nepali-english-cs-sentiment/test.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHNjTEKr41JQ",
        "outputId": "6183c08c-4b2c-4d32-b49d-0bc67aabfab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id\ttext\tsentiment\n",
            "24440\treally right person dinesh sharma regmi\tPositive\n",
            "22099\twhile no hero haruma malak saba banda man parne dinesh saha 😍\tPositive\n",
            "11299\tamit and preeti today performance was awesome,sachai kati chado sakio 🤩😘\tPositive\n",
            "23246\t1/2 futtte nacheko sadikchy sanga hahahaha 🤣😂🤣 lastai comedy\tNeutral\n",
            "18090\tjaba samma minority hunxa muslim taba samma matra respect hunxa... majority huna da ani nepali janta haru tha pauxas\tNegative\n",
            "22257\tma indian ma kam garna lageko 27 years bhayau sir ke hajur me malai ta indian hos bhanne ? plz i want to know\tNeutral\n",
            "27964\tget readi to face nala bandi in nepal\tNeutral\n",
            "27641\trupak sapkota dai nema sundai ma chhati chaudh vyrw aaux\tPositive\n",
            "14419\tthese top leaders are so good at acting infront of camera and public. 🥱 maha nayak raj dai lai pani acting ko class dhina sakcha. 😅\tNegative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_f = '2024_Pahari_Sentiment_Corpus.txt'\n",
        "in_f = ['test.tsv', 'train.tsv', 'val.tsv']\n",
        "in_dir = '/content/nepali-english-cs-sentiment'\n",
        "out_dir = '/content'"
      ],
      "metadata": {
        "id": "ReNnN57Z47E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def append_to_out(in_f:str|Path, out_f:str|Path) -> None:\n",
        "    with open(in_f, 'r') as in_file, open(out_f, mode = 'a', encoding = 'utf-8') as out_file:\n",
        "        for line in in_file:\n",
        "            line = line.strip()\n",
        "            id, text, sentiment = line.split('\\t')\n",
        "            print(text, file = out_file)\n",
        "\n",
        "def combine_to_out(in_dir:str, out_f:str, in_f:list[str]) -> None:\n",
        "    \"\"\"\n",
        "    :param in_dir: Input files directory\n",
        "    :param out_f: Output file directory\n",
        "    :param in_f: Input file names whose contents are added to output files\n",
        "    \"\"\"\n",
        "    in_dir_path = Path(in_dir)\n",
        "    for f in in_dir_path.iterdir():\n",
        "        if f.is_dir():\n",
        "            continue\n",
        "        if f.name in in_f:\n",
        "            append_to_out(f, out_f)"
      ],
      "metadata": {
        "id": "8mZLIj2M5tlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_to_out(in_dir = in_dir, out_f = f\"{out_dir}/{out_f}\", in_f= in_f)"
      ],
      "metadata": {
        "id": "TIY2WRYE7xn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/2024_Pahari_Sentiment_Corpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db6ja9Hl9Cmr",
        "outputId": "c6a094e4-4769-4f89-9988-b91368131388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text\n",
            "really right person dinesh sharma regmi\n",
            "while no hero haruma malak saba banda man parne dinesh saha 😍\n",
            "amit and preeti today performance was awesome,sachai kati chado sakio 🤩😘\n",
            "1/2 futtte nacheko sadikchy sanga hahahaha 🤣😂🤣 lastai comedy\n",
            "jaba samma minority hunxa muslim taba samma matra respect hunxa... majority huna da ani nepali janta haru tha pauxas\n",
            "ma indian ma kam garna lageko 27 years bhayau sir ke hajur me malai ta indian hos bhanne ? plz i want to know\n",
            "get readi to face nala bandi in nepal\n",
            "rupak sapkota dai nema sundai ma chhati chaudh vyrw aaux\n",
            "these top leaders are so good at acting infront of camera and public. 🥱 maha nayak raj dai lai pani acting ko class dhina sakcha. 😅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/2024_Pahari_Sentiment_Corpus.txt /content/drive/MyDrive/MSICE/CM_Text_Corpus/"
      ],
      "metadata": {
        "id": "XftMjF6W9H3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}